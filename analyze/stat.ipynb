{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = '/home/azureuser/cloudfiles/code/Users/e1310988/satellite-te/output'\n",
    "PROBLEM_PREFIX = 'iridium_new_form'\n",
    "\n",
    "INTENSITY_LIST = ['5', '7p5', '10', '12p5', '15']\n",
    "# TEAL_OUTPUT_LIST = [os.path.join(OUTPUT_DIR, f'{PROBLEM_PREFIX}_Int{intensity}_teal') for intensity in INTENSITY_LIST]\n",
    "# LP_OUTPUT_LIST = [os.path.join(OUTPUT_DIR, f'{PROBLEM_PREFIX}_Int{intensity}_lp') for intensity in INTENSITY_LIST]\n",
    "SATE_OUTPUT_LIST_ISL = [os.path.join(OUTPUT_DIR, f'{PROBLEM_PREFIX}_intensity_{intensity}_spaceTE') for intensity in INTENSITY_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TEAL_TEST_LOG_FNAME = 'teal_topo-300_tsz-None_vr-0.2_lr-0.0001_ep-3_bsz-20_layer-6_sample-5_rho-1.0_step-5.csv'\n",
    "# LP_TEST_LOG_FNAME = 'gurobi_topo-300_tsz-None.csv'\n",
    "SATE_TEST_LOG_FNAME = 'spaceTE_topo-10_tsz-None_vr-0.2_lr-0.0001_ep-3_bsz-32_sample-5_rho-1.0_step-5_quantized-False_compiled-False.csv'\n",
    "\n",
    "# teal_df_list = [pd.read_csv(os.path.join(AssetManager.test_log_dir(output), TEAL_TEST_LOG_FNAME)) \\\n",
    "#     for output in TEAL_OUTPUT_LIST]\n",
    "# lp_df_list = [pd.read_csv(os.path.join(AssetManager.test_log_dir(output), LP_TEST_LOG_FNAME)) \\\n",
    "#     for output in LP_OUTPUT_LIST]\"\n",
    "sate_test_list = [pd.read_csv(os.path.join(output, \"test_logs\", SATE_TEST_LOG_FNAME)) \\\n",
    "    for output in SATE_OUTPUT_LIST_ISL]\n",
    "\n",
    "algo_df_dict = {\n",
    "    'SATE': sate_test_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sate_mean = [df.mean() for df in sate_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[topo_idx        999.500000\n",
       " tm_idx          999.500000\n",
       " total_demand    250.776433\n",
       " obj_val         225.802046\n",
       " ratio             0.903891\n",
       " runtime           0.015722\n",
       " dtype: float64,\n",
       " topo_idx        999.500000\n",
       " tm_idx          999.500000\n",
       " total_demand    357.554507\n",
       " obj_val         311.821276\n",
       " ratio             0.876115\n",
       " runtime           0.014977\n",
       " dtype: float64,\n",
       " topo_idx        999.500000\n",
       " tm_idx          999.500000\n",
       " total_demand    460.888626\n",
       " obj_val         376.121984\n",
       " ratio             0.819991\n",
       " runtime           0.015426\n",
       " dtype: float64,\n",
       " topo_idx        999.500000\n",
       " tm_idx          999.500000\n",
       " total_demand    550.635976\n",
       " obj_val         418.277588\n",
       " ratio             0.763027\n",
       " runtime           0.015698\n",
       " dtype: float64,\n",
       " topo_idx        999.500000\n",
       " tm_idx          999.500000\n",
       " total_demand    638.396211\n",
       " obj_val         453.752612\n",
       " ratio             0.713699\n",
       " runtime           0.015592\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sate_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 10 09:57:26 2024\n",
    "\n",
    "@author: WHH\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import lib.data.starlink.MultiShellGraph as MSG\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import networkx as nx\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import lib.data.starlink.SPOnGrid as SPG\n",
    "import lib.data.starlink.ECMP as Baseline1\n",
    "\n",
    "def ECMP(intensity) :\n",
    "    # ========= Parameters to change ==========\n",
    "    DataSetSize = 100 #\n",
    "    fileName = open(f\"/home/azureuser/cloudfiles/code/Users/e1310988/satellite-te/raw_data/starlink/DataSetForSaTE{intensity}/StarLink_DataSetForAgent{intensity}_5000_A.pkl\", \"rb\")\n",
    "    InterConnectedMode = 'ISL'#'GrdStation' # 'ISL'\n",
    "    ISLCap = 50*4\n",
    "    UpLinkCap = 200*4\n",
    "    DownLinkCap = 200*4\n",
    "\n",
    "    # ========= Orbit Shell Parameters =========\n",
    "    OrbitNum1 = 72\n",
    "    SatNum1   = 22\n",
    "\n",
    "    OrbitNum2 = 72\n",
    "    SatNum2   = 22\n",
    "\n",
    "    OrbitNum3 = 58\n",
    "    SatNum3   = 6\n",
    "\n",
    "    OrbitNum4 = 36\n",
    "    SatNum4   = 20\n",
    "\n",
    "    GrdStationNum = 222\n",
    "\n",
    "    # =========== Generate Intra-Shell Static Graph =========\n",
    "    LatMat1 = [0 for i in range(OrbitNum1 * SatNum1)]\n",
    "    LatMat2 = [0 for i in range(OrbitNum2 * SatNum2)]\n",
    "    LatMat3 = [0 for i in range(OrbitNum3 * SatNum3)]\n",
    "    LatMat4 = [0 for i in range(OrbitNum4 * SatNum4)]\n",
    "    LatLimit = 90\n",
    "\n",
    "    Offset1 = 0\n",
    "    Offset2 = OrbitNum1 * SatNum1\n",
    "    Offset3 = OrbitNum1 * SatNum1 + OrbitNum2 * SatNum2\n",
    "    Offset4 = OrbitNum1 * SatNum1 + OrbitNum2 * SatNum2 + OrbitNum3 * SatNum3\n",
    "    Offset5 = OrbitNum1 * SatNum1 + OrbitNum2 * SatNum2 + OrbitNum3 * SatNum3 + OrbitNum4 * SatNum4\n",
    "\n",
    "    G1, EMap1, E1 = MSG.Inter_Shell_Graph(OrbitNum1, SatNum1, LatMat1, Offset1, LatLimit)\n",
    "    G2, EMap2, E2 = MSG.Inter_Shell_Graph(OrbitNum2, SatNum2, LatMat2, Offset2, LatLimit)\n",
    "    G3, EMap3, E3 = MSG.Inter_Shell_Graph(OrbitNum3, SatNum3, LatMat3, Offset3, LatLimit)\n",
    "    G4, EMap4, E4 = MSG.Inter_Shell_Graph(OrbitNum4, SatNum4, LatMat4, Offset4, LatLimit)\n",
    "\n",
    "    G_Trajectory = []\n",
    "    ISL_Trajectory = []\n",
    "    G_interShell_last = []\n",
    "    ISL_interShell_last = []\n",
    "    Result = [[],[],[]]\n",
    "    # =========== Load DataSet ==============\n",
    "    for k in tqdm(range(DataSetSize)):\n",
    "        data = pickle.load(fileName)\n",
    "        G_interShell = data['InterShell_GrdRelay']\n",
    "        ISL_interShell = data['InterShell_ISL']\n",
    "        FlowSet = data['FlowSet']\n",
    "        # print(['Index of Loaded Data:', k])\n",
    "        \n",
    "        # =================================================\n",
    "        # --------------- Generate E and G ----------------\n",
    "        # =================================================\n",
    "        if InterConnectedMode == 'GrdStation':\n",
    "            # Generate E\n",
    "            E_inter = []\n",
    "            for SatIndex in range(len(G_interShell)):\n",
    "                if int(G_interShell[SatIndex]) >= 0:\n",
    "                    E_inter.append([SatIndex, int(G_interShell[SatIndex] + Offset5)])\n",
    "                    E_inter.append([int(G_interShell[SatIndex] + Offset5), SatIndex])    \n",
    "            # G_interShell = np.zeros(4236) - 1\n",
    "            \n",
    "            if not np.array_equal(G_interShell,G_interShell_last):\n",
    "                G_Trajectory.append(k)\n",
    "                G_interShell_last = copy.deepcopy(G_interShell)\n",
    "        else:\n",
    "            # Generate E\n",
    "            E_inter = []\n",
    "            for SatIndex in range(len(ISL_interShell[0])): # 2 to 1\n",
    "                if ISL_interShell[0][SatIndex] >= 0:\n",
    "                    S2 = SatIndex + Offset2 \n",
    "                    S1 = int(ISL_interShell[0][SatIndex])\n",
    "                    E_inter.append([S2, S1])\n",
    "                    E_inter.append([S1, S2])\n",
    "            \n",
    "            for SatIndex in range(len(ISL_interShell[1])): # 3 to 2\n",
    "                if ISL_interShell[1][SatIndex] >= 0:\n",
    "                    S3 = int(SatIndex + Offset3)\n",
    "                    S2 = int(ISL_interShell[1][SatIndex] + Offset2)\n",
    "                    E_inter.append([S3, S2])\n",
    "                    E_inter.append([S2, S3])\n",
    "            \n",
    "            for SatIndex in range(len(ISL_interShell[2])): # 4 to 3\n",
    "                if ISL_interShell[2][SatIndex] >= 0:\n",
    "                    S4 = int(SatIndex + Offset4)\n",
    "                    S3 = int(ISL_interShell[2][SatIndex] + Offset3)\n",
    "                    E_inter.append([S4, S3])\n",
    "                    E_inter.append([S3, S4])\n",
    "            \n",
    "            if ISL_interShell != ISL_interShell_last:\n",
    "                ISL_Trajectory.append(k)\n",
    "                ISL_interShell_last = copy.deepcopy(ISL_interShell)\n",
    "        \n",
    "        E = E1 + E2 + E3 + E4 + E_inter\n",
    "        # print(['Number of Edge:', len(E)])\n",
    "        # Generate G\n",
    "        G = np.zeros((Offset5 + GrdStationNum, Offset5 + GrdStationNum)) + 999\n",
    "        for Edge in E:\n",
    "            G[Edge[0]][Edge[1]] = 1\n",
    "        # =================================================\n",
    "        # sio.savemat('TrackChanges.mat',{'G_Trajectory':G_Trajectory,\n",
    "        #                                 'ISL_Trajectory':ISL_Trajectory})\n",
    "        # ======================== Routing ================\n",
    "        \n",
    "        # E_load = [0 for x in range(len(E))]\n",
    "        # for flow in FlowSet :\n",
    "        #     Path = SPG.SPOnGrid(flow[0],flow[1],\n",
    "        #                     G_interShell, \n",
    "        #                     ISL_interShell, \n",
    "        #                     InterConnectedMode, \n",
    "        #                     5) \n",
    "        #     for p in Path:\n",
    "        #         for node in range(len(p)-1):\n",
    "        #             x = E.index([int(p[node]),int(p[node+1])])\n",
    "        #             E_load[x] = E_load[x] + flow[2]/5\n",
    "        # print(sum(min(200,x) for x in E_load) / sum(x > 0 for x in E_load))\n",
    "        # print(sum(x for x in E_load) / sum(x > 0 for x in E_load))   \n",
    "            # for p in Path:\n",
    "            #     if p[0] != flow[0] or p[-1] != flow[1]:\n",
    "            #         print('Src Des Error!')\n",
    "            #         break\n",
    "            #     p_set = set(p)\n",
    "            #     if len(p_set) != len(p):\n",
    "            #         print('Loop!')\n",
    "            #         break\n",
    "            #     for node in range(len(p)-1):\n",
    "            #         if G[int(p[node])][int(p[node+1])] != 1:\n",
    "            #             print(['Invalid Edge!',int(p[node]), int(p[node+1])])\n",
    "            #             break\n",
    "        # for grd in range(222):\n",
    "        #     print(SPG.SatOverGrdStation(grd,G_interShell))\n",
    "        # ============== ECMP ====================\n",
    "        time_M0 = time.perf_counter()\n",
    "        Throughput, Ratio = Baseline1.ECMP(E,FlowSet,G_interShell,ISL_interShell,InterConnectedMode,ISLCap,UpLinkCap,DownLinkCap)\n",
    "        time_M1 = time.perf_counter()\n",
    "        # print([Throughput, Ratio, time_M1- time_M0])\n",
    "        Result[0].append(Throughput)\n",
    "        Result[1].append(Ratio)\n",
    "        Result[2].append(time_M1- time_M0)\n",
    "\n",
    "    print([sum(Result[0])/len(Result[0]),\n",
    "        sum(Result[1])/len(Result[1]),\n",
    "        sum(Result[2])/len(Result[2])])\n",
    "                \n",
    "        # ================ Isomorphism ==================\n",
    "        # if k == 0:\n",
    "        #     Purified_Topology = []  \n",
    "        # IsANewTopology = 1\n",
    "        # for Paras in Purified_Topology:  \n",
    "        #     start = time.perf_counter()\n",
    "        #     TT = nx.Graph()\n",
    "        #     TT.add_nodes_from([i for i in range(Offset5 + GrdStationNum)])\n",
    "        #     TT.add_edges_from(E)\n",
    "        #     T0 = nx.Graph()\n",
    "        #     T0.add_nodes_from([i for i in range(Offset5 + GrdStationNum)])\n",
    "        #     T0.add_edges_from(E1+E2+E3+E4+Paras)\n",
    "        #     GM = nx.isomorphism.GraphMatcher(T0, TT)\n",
    "        #     # print(GM.is_isomorphic())\n",
    "        #     if nx.is_isomorphic(T0, TT) is True:            \n",
    "        #         # mapping = GM.mapping\n",
    "        #         IsANewTopology = 0\n",
    "        #         break\n",
    "        #     end = time.perf_counter() \n",
    "        #     print(end-start)\n",
    "        # if IsANewTopology == 1:\n",
    "        #     Purified_Topology.append(E_inter)\n",
    "        # print([len(G_Trajectory),len(ISL_Trajectory),len(Purified_Topology)])   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 22 16:44:17 2024\n",
    "\n",
    "@author: admin\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import networkx as nx\n",
    "import scipy.io as sio\n",
    "import ShortestPath as ShP\n",
    "# =========== Import Iridium Topologies ========\n",
    "fileName = open('/home/azureuser/cloudfiles/code/Users/e1310988/satellite-te/raw_data/iridium/Iridium_DataSetForAgent_5_60480.pkl','rb')\n",
    "DataSetSize = 2\n",
    "k = 5\n",
    "\n",
    "OrbitNum = 6\n",
    "SatNum   = 11\n",
    "TotalNum = OrbitNum*SatNum\n",
    "for k in range(DataSetSize):\n",
    "    data = pickle.load(fileName)\n",
    "    FlowSet = data['FlowSet']\n",
    "    E = data['E']\n",
    "    ISLCap = data['ISLCap'] \n",
    "    print(ISLCap)\n",
    "    UpLinkCap = data['UpLinkCap'] \n",
    "    print(UpLinkCap)\n",
    "    DownLinkCap = data['DownLinkCap']\n",
    "    print(DownLinkCap)\n",
    "    G = np.zeros((TotalNum,TotalNum)) + 999\n",
    "    EMap = np.zeros((TotalNum,TotalNum)) + 999\n",
    "    Eindex = 0\n",
    "    for Edge in E:\n",
    "        G[int(Edge[0])][int(Edge[1])] = 1\n",
    "        EMap[Edge[0]][Edge[1]] = Eindex\n",
    "        Eindex += 1\n",
    "\n",
    "    print(k)\n",
    "    for flow in FlowSet:\n",
    "        path_edge = ShP.k_Shortest(G, flow[0], flow[1], k, 999, E, EMap)\n",
    "        Path = []\n",
    "        for p in path_edge:\n",
    "            path_node = []\n",
    "            for e in p['path']:\n",
    "                # print(p)\n",
    "                path_node.append(E[int(e)][0])\n",
    "            path_node.append(E[int(e)][1])\n",
    "            Path.append(path_node)\n",
    "        while len(Path) < 5:\n",
    "            Path.append(Path[0])\n",
    "\n",
    "        Input = [flow[0], flow[1], Path]\n",
    "        \n",
    "        # for p in Path:\n",
    "        #     if p[0] != flow[0] or p[-1] != flow[1]:\n",
    "        #         print('Src Des Error!')\n",
    "        #         break\n",
    "        #     p_set = set(p)\n",
    "        #     if len(p_set) != len(p):\n",
    "        #         print('Loop!')\n",
    "        #         break\n",
    "        #     for node in range(len(p)-1):\n",
    "        #         if G[int(p[node])][int(p[node+1])] != 1:\n",
    "        #             print(['Invalid Edge!',int(p[node]), int(p[node+1])])\n",
    "        #             break\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
