{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections.abc import Iterable\n",
    "import pickle\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively find the size of objects in bytes.\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "\n",
    "    # Mark as seen\n",
    "    seen.add(obj_id)\n",
    "\n",
    "    # If the object is a dictionary, iterate over its items\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    # If the object is an iterable (list, tuple, set, etc.), iterate over its elements\n",
    "    elif isinstance(obj, Iterable) and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    \n",
    "    return size\n",
    "\n",
    "def convert_bytes_to_gb(bytes_size):\n",
    "    return bytes_size / (1024 ** 3)\n",
    "\n",
    "obj = {\n",
    "    'a': [1, 2, 3, 4, 5],\n",
    "    'b': {'x': 10, 'y': 20},\n",
    "    'c': (3.14, 2.71, 1.62),\n",
    "    'd': 'string',\n",
    "    'e': b'bytes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '/home/azureuser/cloudfiles/code/Users/e1310988/satellite-te/input/starlink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_array_to_dict(example_array):\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for index in np.ndindex(example_array.shape):\n",
    "        value = example_array[index]\n",
    "        if value != 0:\n",
    "            indices.append(index)\n",
    "            values.append(value)\n",
    "\n",
    "    result_dict = {'size': example_array.shape[0],'edge_list': np.array(indices), 'weight_list': np.array(values)}\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "def convert_dict_to_array(example_dict):\n",
    "\n",
    "    result_array = np.zeros((example_dict['size'], example_dict['size']), dtype=np.float32)\n",
    "\n",
    "    for index, value in zip(example_dict['edge_list'], example_dict['weight_list']):\n",
    "        result_array[index] = value\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "with open(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    iridium_path = pickle.load(file)\n",
    "\n",
    "iridium_topo = nx.read_gpickle(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_0/graph.gpickle')\n",
    "\n",
    "iridium_tm_train_matrix = []\n",
    "iridium_tm_train_list = []\n",
    "\n",
    "with open(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_1/tm_train.pkl', 'rb') as file:\n",
    "    iridium_tm_train_full = pickle.load(file)\n",
    "\n",
    "for i in range(1, 51):\n",
    "    iridium_tm_train_matrix.append(iridium_tm_train_full[i])\n",
    "    iridium_tm_train_list.append(convert_array_to_dict(iridium_tm_train_full[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.42\n",
      "86460\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in iridium_tm_train_matrix:\n",
    "    tm_num += np.count_nonzero(tm)\n",
    "\n",
    "\n",
    "print(tm_num/len(iridium_tm_train_matrix))\n",
    "\n",
    "print(len(next(iter(iridium_path.values()))) * len(iridium_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from lib.data.starlink.orbit_params import OrbitParams\n",
    "from lib.data.starlink.ism import InterShellMode as ISM\n",
    "from lib.data.starlink.user_node import generate_sat2user\n",
    "\n",
    "\n",
    "def construct_from_edge(edge_list, params):\n",
    "    \"\"\"Construct a networkx graph from a list of edges.\"\"\"\n",
    "\n",
    "    sat2user = generate_sat2user(params.Offset5, params.GrdStationNum, params.ism)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(params.graph_node_num))\n",
    "    ## 1. Inter-satellite links\n",
    "    for e in edge_list:\n",
    "        if (e[0] == e[1]) :\n",
    "            continue\n",
    "        G.add_edge(e[0], e[1], capacity=params.isl_cap)\n",
    "        # G.add_edge(e[1], e[0], capacity=params.isl_cap)\n",
    "    ## 2. User-satellite links\n",
    "    for i in range(params.Offset5):\n",
    "        # Uplink\n",
    "        G.add_edge(sat2user(i), i, capacity=params.uplink_cap)\n",
    "        # Downlink\n",
    "        G.add_edge(i, sat2user(i), capacity=params.downlink_cap)\n",
    "    ## 3. Inter ground station links\n",
    "    for i in range(params.GrdStationNum):\n",
    "        for j in range(params.GrdStationNum):\n",
    "            if i == j:\n",
    "                continue\n",
    "            G.add_edge(i + params.Offset5, j + params.Offset5, capacity=0)\n",
    "            G.add_edge(j + params.Offset5, i + params.Offset5, capacity=0)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    starlink500_path = pickle.load(file)\n",
    "\n",
    "reduced = 8\n",
    "\n",
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=round(2 * 22 * 72 / reduced),\n",
    "    graph_node_num=round(2 * 22 * 72 / reduced) * 2 + 222,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/graph_edge.pickle', 'rb') as file:\n",
    "    starlink500_topo = construct_from_edge(pickle.load(file), params)\n",
    "\n",
    "starlink500_tm_train_list = []\n",
    "starlink500_tm_train_matrix = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/tm_train/{i}.pkl', 'rb') as file:\n",
    "        tm = pickle.load(file)\n",
    "        starlink500_tm_train_list.append(tm)\n",
    "        starlink500_tm_train_matrix.append(convert_dict_to_array(tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in starlink500_tm_train_list:\n",
    "    tm_num += non_zero_count(tm['weight_list'])\n",
    "\n",
    "print(tm_num/len(starlink500_tm_train_list))\n",
    "\n",
    "print(len(next(iter(starlink500_path.values()))) * len(starlink500_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    starlink1500_path = pickle.load(file)\n",
    "\n",
    "reduced = 2\n",
    "\n",
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=round(2 * 22 * 72 / reduced),\n",
    "    graph_node_num= round(2 * 22 * 72 / reduced) * 2+ 222,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/graph_edge.pickle', 'rb') as file:\n",
    "    starlink1500_topo = construct_from_edge(pickle.load(file), params)\n",
    "\n",
    "starlink1500_tm_train_list = []\n",
    "starlink1500_tm_train_matrix = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/tm_train/{i}.pkl', 'rb') as file:\n",
    "        tm = pickle.load(file)\n",
    "        starlink1500_tm_train_list.append(tm)\n",
    "        starlink1500_tm_train_matrix.append(convert_dict_to_array(tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in starlink1500_tm_train_list:\n",
    "    tm_num += non_zero_count(tm['weight_list'])\n",
    "\n",
    "print(tm_num/len(starlink1500_tm_train_list))\n",
    "\n",
    "print(len(next(iter(starlink1500_path.values()))) * len(starlink1500_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_5000_dict_to_tm_list(tm_dict, size):    \n",
    "    # Extract indices and values\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for key, value in tm_dict.items():\n",
    "        index = tuple(map(int, key.split(',')))  # Split the string key and convert to tuple of ints\n",
    "        indices.append(index)\n",
    "        values.append(value)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    \n",
    "    indices_array = np.array(indices)\n",
    "    values_array = np.array(values)\n",
    "\n",
    "    # Construct the result dictionary\n",
    "    result_dict = {'size': size, 'edge_list': indices_array, 'weight_list': values_array}\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=4236,\n",
    "    graph_node_num=8694,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(f'{INPUT_DIR}/DataSetForSaTE100/GrdStation/StarLink_DataSetForAgent100_5000_B.pkl', 'rb') as file:\n",
    "    starlink5000_data = pickle.load(file)\n",
    "\n",
    "starlink5000_path = starlink5000_data[0]['path']\n",
    "starlink5000_topo = construct_from_edge(starlink5000_data[0]['graph'], params)\n",
    "\n",
    "starlink5000_tm_train_list = []\n",
    "starlink5000_tm_train_matrix = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    tm_list = from_5000_dict_to_tm_list(starlink5000_data[i]['tm'], params.graph_node_num)\n",
    "    starlink5000_tm_train_list.append(tm_list)\n",
    "    starlink5000_tm_train_matrix.append(convert_dict_to_array(tm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_num = 0\n",
    "tm_num = 0\n",
    "\n",
    "for i in range(len(starlink5000_data)):\n",
    "    path_num += len(starlink5000_data[i]['path'])\n",
    "    tm_num += len(starlink5000_data[i]['tm'])\n",
    "\n",
    "print(path_num/5000, tm_num/5000)\n",
    "\n",
    "print(len(starlink5000_path['8343, 6455']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iridium_path is not defined, skipping...\n",
      "iridium_topo is not defined, skipping...\n",
      "iridium_tm_train_matrix is not defined, skipping...\n",
      "iridium_tm_train_list is not defined, skipping...\n",
      "starlink500_path is not defined, skipping...\n",
      "starlink500_topo is not defined, skipping...\n",
      "starlink500_tm_train_matrix is not defined, skipping...\n",
      "starlink500_tm_train_list is not defined, skipping...\n",
      "starlink1500_path is not defined, skipping...\n",
      "starlink1500_topo is not defined, skipping...\n",
      "starlink1500_tm_train_matrix is not defined, skipping...\n",
      "starlink1500_tm_train_list is not defined, skipping...\n",
      "Total size of the starlink5000_path: 0.015014640986919403 GB\n",
      "Total size of the starlink5000_topo: 0.00022675469517707825 GB\n",
      "Total size of the starlink5000_tm_train_matrix: 14.079381860792637 GB\n",
      "Total size of the starlink5000_tm_train_list: 0.008303857408463955 GB\n"
     ]
    }
   ],
   "source": [
    "def get_variable_name(obj, global_vars):\n",
    "    matches = [name for name, value in global_vars.items() if value is obj]\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "object_names = [\n",
    "    'iridium_path', 'iridium_topo', 'iridium_tm_train_matrix', 'iridium_tm_train_list',\n",
    "    'starlink500_path', 'starlink500_topo', 'starlink500_tm_train_matrix', 'starlink500_tm_train_list',\n",
    "    'starlink1500_path', 'starlink1500_topo', 'starlink1500_tm_train_matrix', 'starlink1500_tm_train_list',\n",
    "    'starlink5000_path', 'starlink5000_topo', 'starlink5000_tm_train_matrix', 'starlink5000_tm_train_list'\n",
    "]\n",
    "\n",
    "for name in object_names:\n",
    "    if name in globals():\n",
    "        obj = globals()[name]\n",
    "        if not obj:\n",
    "            continue\n",
    "        print(f\"Total size of the {name}: {convert_bytes_to_gb(get_size(obj))} GB\")\n",
    "    else:\n",
    "        print(f\"{name} is not defined, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/data/projects/11003765/sate/input/starlink/starlink_528/GrdStation/StarLink_DataSetForAgent100_5000_Size528.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "\n",
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
