{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections.abc import Iterable\n",
    "import pickle\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively find the size of objects in bytes.\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "\n",
    "    # Mark as seen\n",
    "    seen.add(obj_id)\n",
    "\n",
    "    # If the object is a dictionary, iterate over its items\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    # If the object is an iterable (list, tuple, set, etc.), iterate over its elements\n",
    "    elif isinstance(obj, Iterable) and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    \n",
    "    return size\n",
    "\n",
    "def convert_bytes_to_gb(bytes_size):\n",
    "    return bytes_size / (1024 ** 3)\n",
    "\n",
    "obj = {\n",
    "    'a': [1, 2, 3, 4, 5],\n",
    "    'b': {'x': 10, 'y': 20},\n",
    "    'c': (3.14, 2.71, 1.62),\n",
    "    'd': 'string',\n",
    "    'e': b'bytes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '/home/azureuser/cloudfiles/code/Users/e1310988/satellite-te/input/starlink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "with open(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    iridium_path = pickle.load(file)\n",
    "\n",
    "iridium_topo = nx.read_gpickle(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_0/graph.gpickle')\n",
    "\n",
    "iridium_tm_train = []\n",
    "\n",
    "with open(f'{INPUT_DIR}/../iridium/IridiumDataSet14day20sec_Int15/topo_1/tm_train.pkl', 'rb') as file:\n",
    "    iridium_tm_train_full = pickle.load(file)\n",
    "\n",
    "for i in range(1, 51):\n",
    "    iridium_tm_train.append(iridium_tm_train_full[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in iridium_tm_train:\n",
    "    tm_num += np.count_nonzero(tm)\n",
    "\n",
    "\n",
    "print(tm_num/len(iridium_tm_train))\n",
    "\n",
    "print(len(next(iter(iridium_path.values()))) * len(iridium_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from lib.data.starlink.orbit_params import OrbitParams\n",
    "from lib.data.starlink.ism import InterShellMode as ISM\n",
    "from lib.data.starlink.user_node import generate_sat2user\n",
    "\n",
    "\n",
    "def construct_from_edge(edge_list, params):\n",
    "    \"\"\"Construct a networkx graph from a list of edges.\"\"\"\n",
    "\n",
    "    sat2user = generate_sat2user(params.Offset5, params.GrdStationNum, params.ism)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(params.graph_node_num))\n",
    "    ## 1. Inter-satellite links\n",
    "    for e in edge_list:\n",
    "        if (e[0] == e[1]) :\n",
    "            continue\n",
    "        G.add_edge(e[0], e[1], capacity=params.isl_cap)\n",
    "        # G.add_edge(e[1], e[0], capacity=params.isl_cap)\n",
    "    ## 2. User-satellite links\n",
    "    for i in range(params.Offset5):\n",
    "        # Uplink\n",
    "        G.add_edge(sat2user(i), i, capacity=params.uplink_cap)\n",
    "        # Downlink\n",
    "        G.add_edge(i, sat2user(i), capacity=params.downlink_cap)\n",
    "    ## 3. Inter ground station links\n",
    "    for i in range(params.GrdStationNum):\n",
    "        for j in range(params.GrdStationNum):\n",
    "            if i == j:\n",
    "                continue\n",
    "            G.add_edge(i + params.Offset5, j + params.Offset5, capacity=0)\n",
    "            G.add_edge(j + params.Offset5, i + params.Offset5, capacity=0)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    starlink500_path = pickle.load(file)\n",
    "\n",
    "reduced = 8\n",
    "\n",
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=round(2 * 22 * 72 / reduced),\n",
    "    graph_node_num=round(2 * 22 * 72 / reduced) + 222,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/graph_edge.pickle', 'rb') as file:\n",
    "    starlink500_topo = construct_from_edge(pickle.load(file), params)\n",
    "\n",
    "starlink500_tm_train = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    with open(f'{INPUT_DIR}/starlink_500/GrdStation_teal/topo_0/tm_train/{i}.pkl', 'rb') as file:\n",
    "        starlink500_tm_train.append(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in starlink500_tm_train:\n",
    "    tm_num += non_zero_count(tm['weight_list'])\n",
    "\n",
    "print(tm_num/len(starlink500_tm_train))\n",
    "\n",
    "print(len(next(iter(starlink500_path.values()))) * len(starlink500_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/paths_num-5_edge-disjoint-False_dist-metric-min-hop-dict.pkl', 'rb') as file:\n",
    "    starlink1500_path = pickle.load(file)\n",
    "\n",
    "reduced = 2\n",
    "\n",
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=round(2 * 22 * 72 / reduced),\n",
    "    graph_node_num=round(2 * 22 * 72 / reduced) + 222,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/graph_edge.pickle', 'rb') as file:\n",
    "    starlink1500_topo = construct_from_edge(pickle.load(file), params)\n",
    "\n",
    "starlink1500_tm_train = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    with open(f'{INPUT_DIR}/starlink_1500/GrdStation_teal/topo_0/tm_train/{i}.pkl', 'rb') as file:\n",
    "        starlink1500_tm_train.append(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_count(lst):\n",
    "    return len(list(filter(lambda x: x != 0, lst)))\n",
    "\n",
    "tm_num = 0\n",
    "\n",
    "for tm in starlink1500_tm_train:\n",
    "    tm_num += non_zero_count(tm['weight_list'])\n",
    "\n",
    "print(tm_num/len(starlink1500_tm_train))\n",
    "\n",
    "print(len(next(iter(starlink1500_path.values()))) * len(starlink1500_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrbitParams(\n",
    "    GrdStationNum=222,\n",
    "    Offset5=4236,\n",
    "    graph_node_num=8694,\n",
    "    isl_cap=200,\n",
    "    uplink_cap=800,\n",
    "    downlink_cap=800,\n",
    "    ism=ISM.GRD_STATION,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(f'{INPUT_DIR}/DataSetForSaTE100/GrdStation/StarLink_DataSetForAgent100_5000_B.pkl', 'rb') as file:\n",
    "    starlink5000_data = pickle.load(file)\n",
    "\n",
    "starlink5000_path = starlink5000_data[0]['path']\n",
    "starlink5000_topo = construct_from_edge(starlink5000_data[0]['graph'], params)\n",
    "\n",
    "starlink5000_tm_train = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    starlink5000_tm_train.append(starlink5000_data[i]['tm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_num = 0\n",
    "tm_num = 0\n",
    "\n",
    "for i in range(len(starlink5000_data)):\n",
    "    path_num += len(starlink5000_data[i]['path'])\n",
    "    tm_num += len(starlink5000_data[i]['tm'])\n",
    "\n",
    "print(path_num/5000, tm_num/5000)\n",
    "\n",
    "print(len(starlink5000_path['8343, 6455']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_name(obj, global_vars):\n",
    "    matches = [name for name, value in global_vars.items() if value is obj]\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "object_names = [\n",
    "    'iridium_path', 'iridium_topo', 'iridium_tm_train',\n",
    "    'starlink500_path', 'starlink500_topo', 'starlink500_tm_train',\n",
    "    'starlink1500_path', 'starlink1500_topo', 'starlink1500_tm_train',\n",
    "    'starlink5000_path', 'starlink5000_topo', 'starlink5000_tm_train'\n",
    "]\n",
    "\n",
    "for name in object_names:\n",
    "    if name in globals():\n",
    "        obj = globals()[name]\n",
    "        if not obj:\n",
    "            continue\n",
    "        print(f\"Total size of the {name}: {convert_bytes_to_gb(get_size(obj))} GB\")\n",
    "    else:\n",
    "        print(f\"{name} is not defined, skipping...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
